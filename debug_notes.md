# PCSS-Unet调试与优化笔记

## 问题概述

在软阴影生成项目中，我们发现TensorBoard记录和推理阶段的输出存在不一致的情况，这可能导致训练过程中的可视化结果与实际推理结果不匹配。此外，验证损失在训练约30轮后出现异常波动，这表明训练过程可能存在问题。

## 主要修复

### 1. 推理脚本优化 (infer.py)

- **添加了详细日志**：引入日志系统，便于调试和跟踪推理过程
- **统一数据处理流程**：确保与训练阶段使用相同的数据前处理和后处理步骤
- **添加了混合精度推理**：与训练阶段保持一致，使用`torch.amp.autocast`进行混合精度计算
- **优化内存使用**：使用`torch.inference_mode()`替代`torch.no_grad()`，节省内存开销
- **添加输出统计信息**：记录输出图像的最小值、最大值和均值，便于比较

### 2. 训练脚本优化 (main.py)

- **统一可视化处理**：TensorBoard记录的图像现在与推理输出格式完全一致
- **添加uint8格式可视化**：同时保存float和uint8两种格式的结果，方便对比
- **混合精度参数修正**：修正了`torch.amp.autocast`的参数，确保在不同设备上行为一致
- **验证函数增强**：增加了L1损失监控，方便判断模型表现
- **内存管理优化**：更积极地释放不再需要的张量，减少内存泄漏风险

### 3. 模型优化 (Unetmodel.py)

- **数据类型一致性**：确保模型前向传播过程中的数据类型一致，避免在混合精度训练时出现问题
- **尺寸验证与调整**：增强了对输入图像尺寸的验证，确保是2的倍数

### 4. 损失函数优化 (customLoss.py)

- **VGG损失函数增强**：确保数据类型一致性，防止在混合精度训练时出现数据类型不匹配问题
- **预处理步骤优化**：统一阴影融合到RGB的过程，保证损失计算的稳定性

## 新增验证工具

创建了`validate_consistency.py`工具，用于验证TensorBoard记录的输出与推理脚本生成的输出是否一致。该工具：

- 读取相同的输入文件
- 使用两种不同的处理流程（TensorBoard记录流程和推理脚本流程）
- 保存并比较两种输出的结果
- 计算相似度指标（MSE, PSNR）
- 生成可视化比较图

## 使用方法

### 验证一致性

```bash
python validate_consistency.py --input <你的EXR文件> --weights <你的模型权重文件> --output_dir consistency_test
```

### 进行推理

```bash
python infer.py --input <你的EXR文件> --output <输出PNG文件> --weights <你的模型权重文件> --verbose
```

## 可能的后续优化

1. **批量归一化层重新评估**：在U-Net架构中，可以考虑使用Instance Normalization替代Batch Normalization，特别是当批量大小较小时
2. **梯度累积实现**：对于大尺寸图像或显存有限的情况，可以实现梯度累积以使用更大的"等效批量大小"
3. **学习率策略优化**：考虑引入更复杂的学习率策略，如余弦退火+热重启
4. **数据增强增强**：添加更多的数据增强方法，如随机旋转、缩放、亮度调整等，提高模型泛化能力
5. **EMA模型权重平均**：实现指数移动平均模型权重，可以获得更稳定的推理结果

## 神经网络实现与论文对比分析

### 网络架构对比

**论文中的特点：**
- 使用5层UNet架构，每层包含1个3x3卷积和1个1x1卷积（不是标准的双3x3卷积）
- 使用双线性插值代替转置卷积进行上采样
- 使用代数和（加法）代替连接层合并跳跃连接
- 使用平均池化代替最大池化
- 移除第一层的跳跃连接以减少噪声

**当前实现：**
- 已实现DoubleConv类使用3x3卷积和1x1卷积
- 使用了双线性插值进行上采样（nn.Upsample）
- 使用算术加法实现跳跃连接（如merge6 = up6 + c4）
- 使用了平均池化（nn.AvgPool2d）
- 直接从第二层开始，第一层通过pixel_unshuffle实现了通道重排

### 损失函数比较

**论文中的特点：**
- 结合像素L1损失和VGG-19感知损失
- 添加特殊的扰动损失以提高时间稳定性
- 扰动损失通过对相机和发射器位置进行微小扰动实现

**当前实现：**
- 已实现CustomLoss结合L1和VGG损失
- VGG损失使用了VGG19预训练模型
- 已实现扰动损失（pert_loss.py）用于时间稳定性
- 已添加对扰动损失的TensorBoard记录支持，可以在训练和验证过程中监控

### 要点和改进方向

1. **网络架构**：
   - [X] 网络结构基本符合论文中的描述
   - [X] 已使用平均池化和双线性上采样
   - [X] 使用加法而非连接合并跳跃连接

2. **损失函数**：
   - [X] 已实现L1+VGG损失的组合
   - [X] 已实现扰动损失来提高时间稳定性

3. **优化点**：
   - [ ] 对网络的第一层和最后一层特别处理以优化性能
   - [ ] 考虑根据场景特定需求优化网络深度

### 详细分析与改进建议

#### 1. 第一层优化分析

论文中提到了一个重要优化：将2x2像素块重排为通道，以避免第一层的高分辨率计算。目前的实现已通过`pixel_unshuffle`实现了类似功能：

```python
def rearrange_to_channels(self, x):
    """使用pixel_unshuffle进行输入重排"""
    return F.pixel_unshuffle(x, downscale_factor=2)  # [B,4,H,W] → [B,16,H/2,W/2]
```

这与论文描述的优化相符："instead of feeding the first layer with full resolution input with 4 channels, we feed the second layer directly with quarter resolution input with 16 channels"。

#### 2. 数据处理流程分析

经检查`setdata.py`中的数据处理：
- 输入为4通道EXR文件，这符合论文中提到的输入通道数
- 标签为灰度PNG图像，范围0-1，这也符合论文的输出表示
- 未发现论文中提到的对相机和发射器位置的扰动，但我们已通过`pert_loss.py`在损失计算中实现了类似功能

#### 3. 网络深度优化方案

论文3.6节提出了基于场景阴影尺寸自动选择网络深度的方法。建议实现以下优化：

1. 根据公式 $l=\log_{2}(p_{w}/3)$ 计算所需网络层数，其中$p_{w}$是阴影过渡区宽度
2. 实现一个自动测量训练集中阴影过渡区宽度的函数
3. 提供不同深度的网络变体（3层、5层、7层）并自动选择最适合的深度

#### 4. 时间稳定性评估

已实现扰动损失，但需要添加客观评估方法：
- 实现论文中提到的时间不稳定性度量：$E=\frac{1}{P}\sum_{p,t}\left\{\exp\left(αD_{t}(p)\right)-1\right\}$
- 对比使用和不使用扰动损失时的结果

### 完整改进计划与下一步工作

1. **网络深度自适应**：
   - [ ] 实现自动测量阴影过渡区宽度的函数
   - [ ] 提供3层、5层、7层网络配置选项
   - [ ] 添加根据输入自动选择最优网络深度的功能

2. **时间稳定性评估**：
   - [ ] 完善时间不稳定性测量函数
   - [ ] 添加基准测试脚本比较不同损失函数
   - [ ] 可视化显示扰动损失对稳定性的改进

3. **性能优化**：
   - [ ] 探索第一/最后层的进一步优化机会
   - [ ] 考虑添加半精度训练和推理支持
   - [ ] 测量并记录网络的实时性能

4. **可视化与分析工具**：
   - [X] 添加TensorBoard记录支持，包括L1、VGG和扰动损失
   - [ ] 添加阴影质量对比工具
   - [ ] 实现论文中的可视化案例
   - [ ] 记录并分析不同参数对结果的影响

## 最近更新

### 2024-03-27: 增强损失函数对软阴影的敏感度
- 添加高频细节损失，提高小物体阴影和边缘清晰度
- 引入半影区域专门处理机制，增强软阴影渐变效果
- 提高VGG中层特征权重(0.2, 0.25, 0.3, 0.15, 0.1)，强化中等尺度阴影特征

### 2024-03-24: 修复显存估算函数错误
- 修复了显存估算函数中"too many values to unpack (expected 3)"错误
- 增加了对4维图像尺寸格式(batch, channels, height, width)的兼容性
- 提高了批量大小自动调整的准确性

### 2024-03-24: 优化VGG特征层权重分配
- 调整VGG特征层权重：(0.1, 0.1, 0.2, 0.3, 0.3) → (0.25, 0.25, 0.2, 0.15, 0.15)
- 增强浅层特征(层2,7)权重，从20%提高到50%，以改善软阴影边缘渐变效果
- 降低深层特征(层21,30)权重，从60%降低到30%，减少阴影边缘"跳变"现象
- 保持中层特征(层12)权重不变，作为浅层和深层特征的平衡

### 2024-03-22: 优化多层VGG特征损失函数
- 用多层特征替换单层特征，提高感知损失的全面性
- 使用五个特定特征层(2, 7, 12, 21, 30)并为每层设置权重
- 简化了图像预处理流程，直接使用输出和目标比较
- 改进了单通道到RGB的转换方式，使用更适合灰度图的归一化参数
- 添加了扰动损失选项，可提高时间稳定性

### 2024-03-22: 修复VGGLoss中的数值不稳定问题
- 增强了VGGLoss中的数值稳定性，防止NaN和Inf梯度传播
- 主要修复内容：
  - 为所有输入添加范围裁剪（clamp）和无效值修复（nan_to_num）
  - 在归一化操作中添加epsilon防止除零错误
  - 在各处理阶段添加安全检查，防止无效值传播
  - 引入异常捕获机制，确保即使出错也能继续训练
- 此修复解决了"Function 'ToCopyBackward0' returned nan values"错误
- 针对图像预处理环节进行了额外优化，确保阴影融合过程的数值稳定性

### 2024-03-22: 实现智能梯度修复机制
- 新增基于无效梯度比例的分级处理机制：
  - 当无效梯度（NaN/Inf）比例>20%时，跳过整个批次
  - 当无效梯度比例<=20%时，进行智能修复而非放弃批次
- 实现了针对性的梯度替换策略：
  - NaN值替换为有效梯度均值加少量随机噪声
  - Inf值替换为有效梯度最大值的有符号10倍
  - 无有效梯度参考时，将整个梯度置零
- 此机制提高了训练稳定性和数据利用率，减少了因偶发梯度问题导致的训练中断

### 2024-03-21: 修复梯度缩放相关的类型错误
- 修复了`unscale_() has already been called`错误，确保混合精度训练中梯度只被unscale一次
- 添加缺失的`traceback`模块导入
- 改进了梯度检查逻辑：先检查缩放后的梯度，再检查未缩放的梯度
- 为不同检查阶段添加了更详细的日志，便于诊断梯度问题

### 2024-03-21: 修复了梯度处理的重大错误
- 修复了`unscale_() has already been called`错误，确保混合精度训练中梯度只被unscale一次
- 添加缺失的`traceback`模块导入
- 改进了梯度检查逻辑：先检查缩放后的梯度，再检查未缩放的梯度
- 为不同检查阶段添加了更详细的日志，便于诊断梯度问题

### 2024-03-21: 优化梯度爆炸问题处理
- 重构了梯度监控钩子系统，只监控不修改梯度值以防止冲突
- 扩大了梯度钩子注册范围，覆盖所有网络模块和损失函数
- 添加了更严格的梯度检查机制，发现NaN或Inf梯度时跳过整个批次更新
- 引入学习率预热（Warmup）机制，稳定训练初期
- 使用余弦衰减学习率调度，避免学习率突变导致的不稳定
- 降低了梯度裁剪阈值，从自适应值降至固定的1.0
- 添加了warmup_epochs配置选项，支持调整预热轮数

### 2024-03-21: 增强了正则化和验证方法
- 添加了Dropout2d层到UNet模型中，提高了正则化效果
- 为优化器添加了权重衰减(weight decay)参数，进一步防止过拟合
- 实现了不分块的直接验证函数validate_direct，替代原来的分块验证方法
- 添加了optimizer_type和dropout_rate配置项，支持调整优化策略
- 默认使用AdamW优化器，提供了更好的正则化效果